{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Recommenders contributors.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SASRec \n",
    "\n",
    "Self-Attentive Sequential Recommendation (SASRec) [1], is a sequential recommendation system model that uses self-attention mechanisms to capture the sequential patterns in user-item interactions. It is designed to predict the next item a user is likely to interact with based on their previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.pandas_df_utils import filter_k_interactions\n",
    "from recommenders.models.unirec.data.dataset.movielens_utils import merge_category\n",
    "from recommenders.models.unirec.model.sequential.sasrec import SASRec\n",
    "\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = \"100k\"\n",
    "\n",
    "USER_COL = \"userId\"\n",
    "ITEM_COL = \"movieId\"\n",
    "ITEM_SEQ_COL = \"item_seq\"\n",
    "RATING_COL = \"rating\"\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "GENRE_COL = \"genre\"\n",
    "CATEGORY_COL = \"cateId\"\n",
    "\n",
    "OUTPATH = \".\"\n",
    "FULL_USER_HISTORY_PATH = os.path.join(OUTPATH, \"full_user_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[USER_COL, ITEM_COL, RATING_COL, TIMESTAMP_COL],\n",
    "    genres_col=GENRE_COL,\n",
    "    local_cache_path=OUTPATH,\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_df = df[[ITEM_COL, GENRE_COL]].drop_duplicates()\n",
    "print(cate_df.shape)\n",
    "cate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique genres from the data\n",
    "all_genres = set(genre for genre_string in cate_df[GENRE_COL] for genre in genre_string.split(\"|\"))\n",
    "\n",
    "# Create a mapping from genre to ID (1-based index)\n",
    "genre_to_id = {genre: idx + 1 for idx, genre in enumerate(all_genres)}\n",
    "\n",
    "# Map genres to IDs using the dynamic mapping\n",
    "cate_df[CATEGORY_COL] = cate_df[GENRE_COL].apply(\n",
    "    lambda x: [genre_to_id[genre] for genre in x.split(\"|\") if genre in genre_to_id]\n",
    ")\n",
    "\n",
    "print(\"Genre to ID Mapping:\", {genre: id for genre, id in genre_to_id.items()})\n",
    "print(\"Number of unique genres:\", len(all_genres))\n",
    "cate_df.drop(columns=[GENRE_COL], inplace=True)\n",
    "cate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[GENRE_COL], inplace=True)\n",
    "rating_df = pd.merge(df, cate_df, how=\"inner\", on=[ITEM_COL])\n",
    "\n",
    "# Merge categories containing a small number of items (lower than min_item_in_cate) into one category, and get the new mappings\n",
    "cate2idx, item2cate, num_cates = merge_category(rating_df, min_item_in_cate=50)\n",
    "\n",
    "print(\"New genre to ID Mapping:\", {genre: id for genre, id in cate2idx.items()})\n",
    "# print(item2cate)\n",
    "print(\"Number of unique genres:\", num_cates)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only positive interactions\n",
    "data = rating_df.sort_values(by=[USER_COL, TIMESTAMP_COL], ignore_index=True)\n",
    "print(\"original dataset size: {0}\".format(data.shape))\n",
    "data = data[data[\"rating\"] >= 3].reset_index(drop=True)\n",
    "data = data.drop_duplicates(subset=[USER_COL, ITEM_COL], keep=\"last\").reset_index(drop=True)\n",
    "print(\"filter by rating>=3 dataset size: {0}\".format(data.shape))\n",
    "\n",
    "# Filter out users and items with less than k interactions\n",
    "data = filter_k_interactions(data, user_k=10, item_k=10, user_col=USER_COL, item_col=ITEM_COL)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"k filtered dataset size: {0}\".format(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "users = data[USER_COL].unique()\n",
    "items = data[ITEM_COL].unique()\n",
    "num_users, num_items = len(users), len(items)\n",
    "user_id_map = {id: i+1 for i, id in enumerate(users)}\n",
    "item_id_map = {id: i+1 for i, id in enumerate(items)}\n",
    "map_info = {\"user\": {str(k): v for k, v in user_id_map.items()}, \n",
    "            \"item\": {str(k): v for k, v in item_id_map.items()}, \n",
    "            \"cate\": {str(k): v for k, v in cate2idx.items()}}\n",
    "print(f\"Number of users: {num_users}, Number of items: {num_items}, Number of categories: {num_cates}\")\n",
    "\n",
    "data[USER_COL] = data[USER_COL].apply(lambda x: user_id_map[x])\n",
    "data[ITEM_COL] = data[ITEM_COL].apply(lambda x: item_id_map[x])\n",
    "data[CATEGORY_COL] = data[ITEM_COL].apply(lambda x: item2cate[x])\n",
    "itemid2cate = data.set_index(ITEM_COL)[CATEGORY_COL].to_dict()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate full user item sequence\n",
    "data = data[[USER_COL, ITEM_COL, CATEGORY_COL]]\n",
    "full_user_history = data.groupby(by=USER_COL, as_index=False).agg(list).reset_index(drop=True)\n",
    "full_user_history[ITEM_SEQ_COL] = full_user_history[ITEM_COL].apply(lambda x: \",\".join(map(str,x)))\n",
    "full_user_history = full_user_history[[USER_COL, ITEM_SEQ_COL]]\n",
    "full_user_history.to_csv(FULL_USER_HISTORY_PATH, index=False, sep='\\t')\n",
    "full_user_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "\\[1\\] Wang-Cheng Kang, and Julian McAuley, *Self-Attentive Sequential Recommendation*, arXiv preprint arXiv:1808.09781, 2018. <br>\n",
    "\n",
    "\\[2\\] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin, *Attention is all you need*, in Advances in Neural Information Processing Systems, 5998–6008, 2017. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommenders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
